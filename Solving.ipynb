{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Bank Projet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we address the challenge of customer retention for Beta Bank, an institution that faces a recurring problem: customer churn. Each month, a percentage of users leave the bank, generating significant costs, as attracting new customers is often more expensive than retaining current ones. <br>\n",
    "\n",
    "The main objective is to develop a machine learning model capable of predicting whether a customer is likely to leave the bank in the near future. To achieve this, we rely on historical data that reflects customer behavior and contract termination with the institution. <br>\n",
    "\n",
    "The focus is on optimizing the model to achieve the highest possible value of the F1 metric, with a minimum required value of 0.59 on the test set to consider the project successful. Additionally, the AUC-ROC metric will be evaluated to provide a more complete view of the model's performance and compare it with the F1 value. <br>\n",
    "\n",
    "This analysis will allow Beta Bank to identify at-risk customers early and take proactive measures to improve their experience, thereby strengthening the customer-bank relationship and reducing the churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries import.\n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import.\n",
    "\n",
    "df= pd.read_csv('/Users/pauli/Documents/Data/beta_bank/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data inspect.\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initial inspection shows that there are null values ​​in the Tenure column, and columns that are of type string, which must be reviewed later since the models have conflicts with these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            0\n",
       "CustomerId           0\n",
       "Surname              0\n",
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, let's check for missing values.\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check if the rows with NaN in Tenure correspond only to customers who stayed or if there are also customers who left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "30         31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48         49    15766205        Yin          550   Germany    Male   38   \n",
       "51         52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53         54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60         61    15651280     Hunter          742   Germany    Male   35   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "30     NaN       0.00              3          1               0   \n",
       "48     NaN  103391.38              1          0               1   \n",
       "51     NaN  146050.97              2          0               0   \n",
       "53     NaN  125561.97              1          0               0   \n",
       "60     NaN  136857.00              1          0               0   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "30        140469.38       1  \n",
       "48         90878.13       0  \n",
       "51         86424.57       0  \n",
       "53        164040.94       1  \n",
       "60         84509.57       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan= df.query('Tenure.isna()')\n",
    "nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    726\n",
      "Name: count, dtype: int64\n",
      "Exited\n",
      "1    183\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count how many customers containing NaN left or stayed to see if they affect the sample\n",
    "\n",
    "current_client= nan[nan['Exited'] == 0]\n",
    "not_client = nan[nan['Exited'] == 1]\n",
    "\n",
    "print(current_client['Exited'].value_counts())\n",
    "print(not_client['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the rows with null values, 726 correspond to customers who left, this is a significant sample and they cannot be eliminated, so they will be replaced with the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tenure_mean= df['Tenure'].mean()\n",
    "\n",
    "df['Tenure'] = df['Tenure'].fillna(tenure_mean)\n",
    "\n",
    "#Check that there are no more NaNs.\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the RowNumber, Customer Id and Surname columns are removed since they do not represent important categories when creating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(['CustomerId', 'RowNumber', 'Surname'], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data division and transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, we'll split the data into training, validation, and test sets. We'll also transform categorical features into numerical features using One-Hot Encoding (OHE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  float64\n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  bool   \n",
      " 10  Geography_Spain    10000 non-null  bool   \n",
      " 11  Gender_Male        10000 non-null  bool   \n",
      "dtypes: bool(3), float64(3), int64(6)\n",
      "memory usage: 732.6 KB\n"
     ]
    }
   ],
   "source": [
    "#OHE\n",
    "\n",
    "df_ohe= pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "#Test that it was done correctly.\n",
    "\n",
    "df_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6000, 11)\n",
      "Validation set: (2000, 11)\n",
      "Test set: (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "#Divide the dataset into training and validation sets.\n",
    "\n",
    "features= df_ohe.drop(['Exited'], axis=1)\n",
    "target= df_ohe['Exited']\n",
    "\n",
    "# First it is divided into training set (60%) and temporary set (40%)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(features, target, test_size=0.4, random_state=15)\n",
    "\n",
    "#Then the temporary set is divided into validation (20%) and test (20%)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_temp, target_temp, test_size=0.5, random_state=15)\n",
    "\n",
    "#Display the size of the sets\n",
    "\n",
    "print(\"Training set:\", features_train.shape)\n",
    "print(\"Validation set:\", features_valid.shape)\n",
    "print(\"Test set:\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model without considering imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.02358490566037736\n",
      "AUC-ROC: 0.6626656193201742\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=15,  solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "valid_predictions = model.predict(features_valid)\n",
    "\n",
    "# Class predictions (for F1-score)\n",
    "pred_valid = model.predict(features_test)\n",
    "\n",
    "# Probability predictions (for AUC-ROC)\n",
    "prob_one_valid = model.predict_proba(features_test)[:, 1]\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1 = f1_score(target_test, pred_valid)\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Calculate the AUC-ROC\n",
    "auc_roc = roc_auc_score(target_test, prob_one_valid)\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score is extremely low (0.023), indicating that the model performs poorly in balancing accuracy and sensitivity. The model is failing to correctly capture the positive class (customers who leave the bank). <br>\n",
    "The AUC-ROC is 0.66, which, although better than chance (0.5%), is far from excellent, as we ideally seek values ​​closer to 1.0. <br> This proves that the classes are unbalanced; the model is prioritizing the majority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve model quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try two different approaches to balancing classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.6687898089171974\n",
      "AUC-ROC: 0.7025931928687196\n"
     ]
    }
   ],
   "source": [
    "#Option 1: Subsampling the Majority Class\n",
    "\n",
    "\n",
    "df_concat= pd.concat([features, target], axis=1)\n",
    "\n",
    "#Separate the classes\n",
    "\n",
    "class_majority = df_concat[df_concat['Exited'] == 0]\n",
    "class_minority = df_concat[df_concat['Exited'] == 1]\n",
    "\n",
    "# Subsample the majority class\n",
    "\n",
    "class_majority_downsampled = resample(class_majority, replace=False, n_samples=len(class_minority),random_state=15)\n",
    "\n",
    "#Combine balanced classes\n",
    "\n",
    "balanced_df = pd.concat([class_majority_downsampled, class_minority])\n",
    "\n",
    "#Divide the data\n",
    "\n",
    "X_balanced_downsampled = balanced_df.drop(columns='Exited')\n",
    "y_balanced_downsampled = balanced_df['Exited']\n",
    "\n",
    "\n",
    "X_train_downsampled, X_test_downsampled, y_train_downsampled, y_test_downsampled = train_test_split(X_balanced_downsampled, y_balanced_downsampled, test_size=0.3, random_state=15)\n",
    "\n",
    "# Train the model with balanced data\n",
    "model = LogisticRegression(random_state=15, solver='liblinear')\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "y_pred_downsampled = model.predict(X_test_downsampled)\n",
    "f1 = f1_score(y_test_downsampled, y_pred_downsampled)\n",
    "auc_roc = roc_auc_score(y_test_downsampled, model.predict_proba(X_test_downsampled)[:, 1])\n",
    "\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"AUC-ROC: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.6564822460776218\n",
      "AUC-ROC: 0.7005813423723871\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Oversampling the minority class.\n",
    "\n",
    "\n",
    "#Oversampling the minority class\n",
    "class_minority_oversampled = class_minority.sample(n=len(class_majority), replace=True, random_state=15)\n",
    "\n",
    "#Combine balanced classes\n",
    "oversampled_data = pd.concat([class_majority, class_minority_oversampled])\n",
    "\n",
    "# Shuffle the data\n",
    "oversampled_data = shuffle(oversampled_data, random_state=15)\n",
    "\n",
    "# Divide data\n",
    "X_oversampled = oversampled_data.drop(columns=target.name)\n",
    "y_oversampled = oversampled_data[target.name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_oversampled, y_oversampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "\n",
    "model = LogisticRegression(random_state=15, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 score improved significantly in both cases, indicating a better balance between accuracy and sensitivity in identifying churning customers. For this specific case, we'll use Undersampling due to its better performance on both metrics. It also avoids the overfitting issues associated with oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "F1-Score: 0.6688\n",
      "AUC-ROC: 0.7026\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.65       617\n",
      "           1       0.65      0.69      0.67       606\n",
      "\n",
      "    accuracy                           0.66      1223\n",
      "   macro avg       0.66      0.66      0.66      1223\n",
      "weighted avg       0.66      0.66      0.66      1223\n",
      "\n",
      "Confusion matrix:\n",
      "[[387 230]\n",
      " [186 420]]\n"
     ]
    }
   ],
   "source": [
    "#Option 1: Logistic regression\n",
    "\n",
    "\n",
    "model = LogisticRegression(random_state=15, solver='liblinear')\n",
    "model.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "#Predict on the test set\n",
    "y_pred = model.predict(X_test_downsampled)\n",
    "y_pred_proba = model.predict_proba(X_test_downsampled)[:, 1]\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test_downsampled, y_pred)\n",
    "auc_roc = roc_auc_score(y_test_downsampled, y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics:\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "\n",
    "# Classification report and confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_downsampled, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_downsampled, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "F1-Score: 0.7228\n",
      "AUC-ROC: 0.7810\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       617\n",
      "           1       0.74      0.71      0.72       606\n",
      "\n",
      "    accuracy                           0.73      1223\n",
      "   macro avg       0.73      0.73      0.73      1223\n",
      "weighted avg       0.73      0.73      0.73      1223\n",
      "\n",
      "Confusion matrix:\n",
      "[[465 152]\n",
      " [177 429]]\n"
     ]
    }
   ],
   "source": [
    "# Option 2: Decision Tree Classifier\n",
    "\n",
    "\n",
    "tree_model = DecisionTreeClassifier(random_state=15, max_depth=10)\n",
    "tree_model.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "#Predict on the test set\n",
    "y_pred = tree_model.predict(X_test_downsampled)\n",
    "y_pred_proba = tree_model.predict_proba(X_test_downsampled)[:, 1]\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test_downsampled, y_pred)\n",
    "auc_roc = roc_auc_score(y_test_downsampled, y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics:\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_downsampled, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_downsampled, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics:\n",
      "F1-Score: 0.7605\n",
      "AUC-ROC: 0.8489\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77       617\n",
      "           1       0.78      0.74      0.76       606\n",
      "\n",
      "    accuracy                           0.77      1223\n",
      "   macro avg       0.77      0.77      0.77      1223\n",
      "weighted avg       0.77      0.77      0.77      1223\n",
      "\n",
      "Confusion matrix:\n",
      "[[488 129]\n",
      " [155 451]]\n"
     ]
    }
   ],
   "source": [
    "# Option 3: Random Forest Classifier\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=15, n_estimators=50, max_depth=10)\n",
    "rf_model.fit(X_train_downsampled, y_train_downsampled)\n",
    "\n",
    "y_pred = rf_model.predict(X_test_downsampled)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_downsampled)[:, 1]\n",
    "\n",
    "\n",
    "f1 = f1_score(y_test_downsampled, y_pred)\n",
    "auc_roc = roc_auc_score(y_test_downsampled, y_pred_proba)\n",
    "\n",
    "\n",
    "print(\"Evaluation metrics:\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_downsampled, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test_downsampled, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs decently, but it is the lowest among the three models, so it is discarded. <br> Decision Tree shows a significant improvement in both metrics compared to logistic regression.\n",
    "It has a better balance between precision and recall, but may be less robust. <br>\n",
    "Finally, Random Forest performs best in all metrics, also generalizes better and shows a solid balance between classes. It is also observed that for class 1 (customer who churns) it yielded 494 correctly classified items and 123 misclassified items, and for class 0 it yielded 449 correctly classified items and 157 misclassified items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we sought to predict customer churn at Beta Bank using historical data and a machine learning-based approach. After analyzing several models, class balancing techniques, such as undersampling and oversampling, were implemented to address data imbalance. <br>\n",
    "\n",
    "Of the three models evaluated (Logistic Regression, Decision Tree, and Random Forest), the Random Forest model proved to be the most effective, achieving an F1 score of 0.762 and an AUC-ROC of 0.849. This indicates an excellent balance between precision and recall, as well as a good ability to differentiate between customers who churn and those who remain with the bank. <br>\n",
    "\n",
    "Analysis of the Random Forest model's confusion matrix highlighted its ability to minimize classification errors, both in customers who do not churn (Class 0) and those who do (Class 1). This makes it a reliable tool for identifying customers at risk of churn and designing personalized retention strategies."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 347,
    "start_time": "2024-12-19T22:18:04.345Z"
   },
   {
    "duration": 30,
    "start_time": "2024-12-19T22:18:27.599Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-19T22:18:51.206Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-19T22:18:55.857Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-19T22:20:04.104Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-19T22:20:07.777Z"
   },
   {
    "duration": 158,
    "start_time": "2024-12-19T23:36:23.528Z"
   },
   {
    "duration": 347,
    "start_time": "2024-12-19T23:36:32.540Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-19T23:36:32.889Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-19T23:36:32.910Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-19T23:36:32.930Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-19T23:36:32.943Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-19T23:37:58.017Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-19T23:38:04.313Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-19T23:38:22.670Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-19T23:38:28.618Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-19T23:41:42.878Z"
   },
   {
    "duration": 173,
    "start_time": "2024-12-19T23:44:00.033Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-19T23:44:02.993Z"
   },
   {
    "duration": 12,
    "start_time": "2024-12-19T23:44:10.780Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-19T23:44:14.975Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-19T23:44:28.338Z"
   },
   {
    "duration": 18,
    "start_time": "2024-12-19T23:44:52.683Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-19T23:45:07.369Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-19T23:45:46.713Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-19T23:46:40.047Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:54:25.035Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-19T23:55:11.278Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-19T23:55:54.903Z"
   },
   {
    "duration": 5,
    "start_time": "2024-12-20T00:58:29.279Z"
   },
   {
    "duration": 664,
    "start_time": "2024-12-20T00:58:35.598Z"
   },
   {
    "duration": 35,
    "start_time": "2024-12-20T00:58:56.607Z"
   },
   {
    "duration": 34,
    "start_time": "2024-12-20T00:59:22.376Z"
   },
   {
    "duration": 288,
    "start_time": "2024-12-20T01:00:55.322Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-20T01:00:55.613Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-20T01:00:55.637Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-20T01:00:55.653Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-20T01:00:55.665Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-20T01:00:55.673Z"
   },
   {
    "duration": 34,
    "start_time": "2024-12-20T01:00:55.690Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-20T01:00:55.726Z"
   },
   {
    "duration": 799,
    "start_time": "2024-12-20T01:00:55.735Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-20T01:01:41.266Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-20T01:14:00.494Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-20T01:14:25.498Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-20T01:14:31.905Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-20T01:22:30.743Z"
   },
   {
    "duration": 400,
    "start_time": "2024-12-20T01:22:58.388Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-20T01:23:01.833Z"
   },
   {
    "duration": 16,
    "start_time": "2024-12-20T01:30:01.727Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-20T01:31:39.465Z"
   },
   {
    "duration": 126,
    "start_time": "2024-12-20T01:31:45.822Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-20T01:32:08.055Z"
   },
   {
    "duration": 34,
    "start_time": "2024-12-20T01:32:11.207Z"
   },
   {
    "duration": 1853,
    "start_time": "2024-12-20T01:42:58.610Z"
   },
   {
    "duration": 272,
    "start_time": "2024-12-20T01:46:06.561Z"
   },
   {
    "duration": 109,
    "start_time": "2024-12-20T01:59:57.380Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-20T02:01:28.982Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-20T02:02:44.252Z"
   },
   {
    "duration": 19,
    "start_time": "2024-12-20T02:02:57.079Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-20T02:03:03.772Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-20T02:06:54.657Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-20T02:15:08.981Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-20T02:24:54.429Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-20T02:27:39.695Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-20T02:29:23.850Z"
   },
   {
    "duration": 24,
    "start_time": "2024-12-20T02:29:42.428Z"
   },
   {
    "duration": 2,
    "start_time": "2024-12-20T02:30:20.108Z"
   },
   {
    "duration": 44,
    "start_time": "2024-12-20T02:30:23.200Z"
   },
   {
    "duration": 2603,
    "start_time": "2024-12-21T16:44:22.839Z"
   },
   {
    "duration": 25,
    "start_time": "2024-12-21T16:44:25.445Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-21T16:44:25.471Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-21T16:44:25.485Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-21T16:44:25.499Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-21T16:44:25.506Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-21T16:44:25.519Z"
   },
   {
    "duration": 6,
    "start_time": "2024-12-21T16:44:25.548Z"
   },
   {
    "duration": 9,
    "start_time": "2024-12-21T16:44:25.556Z"
   },
   {
    "duration": 14,
    "start_time": "2024-12-21T16:44:25.567Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-21T16:44:25.582Z"
   },
   {
    "duration": 307,
    "start_time": "2024-12-21T16:44:25.591Z"
   },
   {
    "duration": 46,
    "start_time": "2024-12-21T16:44:25.900Z"
   },
   {
    "duration": 121,
    "start_time": "2024-12-21T16:44:25.949Z"
   },
   {
    "duration": 274,
    "start_time": "2024-12-21T16:50:57.724Z"
   },
   {
    "duration": 73,
    "start_time": "2024-12-21T16:51:14.071Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-21T16:52:21.883Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-21T17:05:54.618Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-21T17:05:57.567Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-21T17:06:04.256Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-21T17:17:32.892Z"
   },
   {
    "duration": 22,
    "start_time": "2024-12-21T17:19:05.407Z"
   },
   {
    "duration": 8,
    "start_time": "2024-12-21T17:20:25.444Z"
   },
   {
    "duration": 153,
    "start_time": "2024-12-21T17:21:11.400Z"
   },
   {
    "duration": 27,
    "start_time": "2024-12-21T17:36:38.300Z"
   },
   {
    "duration": 3,
    "start_time": "2024-12-21T17:36:50.015Z"
   },
   {
    "duration": 740,
    "start_time": "2024-12-22T17:05:12.710Z"
   },
   {
    "duration": 23,
    "start_time": "2024-12-22T17:05:13.453Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-22T17:05:13.477Z"
   },
   {
    "duration": 10,
    "start_time": "2024-12-22T17:05:13.493Z"
   },
   {
    "duration": 21,
    "start_time": "2024-12-22T17:05:13.506Z"
   },
   {
    "duration": 13,
    "start_time": "2024-12-22T17:05:13.528Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-22T17:05:13.542Z"
   },
   {
    "duration": 7,
    "start_time": "2024-12-22T17:05:13.550Z"
   },
   {
    "duration": 11,
    "start_time": "2024-12-22T17:05:13.559Z"
   },
   {
    "duration": 15,
    "start_time": "2024-12-22T17:05:13.572Z"
   },
   {
    "duration": 42,
    "start_time": "2024-12-22T17:05:13.588Z"
   },
   {
    "duration": 31,
    "start_time": "2024-12-22T17:05:13.632Z"
   },
   {
    "duration": 82,
    "start_time": "2024-12-22T17:05:13.665Z"
   },
   {
    "duration": 119,
    "start_time": "2024-12-22T17:05:13.825Z"
   },
   {
    "duration": 89,
    "start_time": "2024-12-22T17:05:13.946Z"
   },
   {
    "duration": 100,
    "start_time": "2024-12-22T17:05:14.037Z"
   },
   {
    "duration": 177,
    "start_time": "2024-12-22T17:05:14.138Z"
   }
  ],
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
